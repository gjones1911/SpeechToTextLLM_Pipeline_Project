{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78feee89-54fd-4a5e-9313-ba4202543dad",
   "metadata": {},
   "source": [
    "# ‚ñ∂Ô∏è Imports and object Creation‚ùóÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2638b921-4258-432e-b587-322d1b76c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os wdir:  /home/gerald/GITS_REPOS/GIT_PLAY_GROUNDs/SpeechToTextLLM_Pipeline_Project/code\n",
      "ü§ñ >> 'mistralai/Mistral-7B-Instruct-v0.2'\n",
      "ü§ñ >> 'NousResearch/Nous-Hermes-2-Mistral-7B-DPO'\n",
      "ü§ñ >> 'teknium/OpenHermes-2.5-Mistral-7B'\n",
      "ü§ñ >> 'microsoft/phi-2'\n",
      "ü§ñ >> 'microsoft/phi-3-mini-4k-instruct'\n",
      "ü§ñ >> 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
      "ü§ñ >> 'OpenAccessAI/MythoMax-L2-13b'\n",
      "ü§ñ >> 'openchat/openchat-3.5-0106'\n",
      "/home/gerald/venvs/sttttsvenv/bin/python\n",
      "cwd:  /home/gerald/GITS_REPOS/GIT_PLAY_GROUNDs/SpeechToTextLLM_Pipeline_Project/code\n"
     ]
    }
   ],
   "source": [
    "from voice_processing.multi_engine_stt import * \n",
    "from voice_processing.multi_engine_tts import *\n",
    "from llm_agent_linux_package.pipeline_agents import *\n",
    "import gradio as gr\n",
    "import signal\n",
    "import time\n",
    "import sys\n",
    "import tempfile\n",
    "import os\n",
    "print(sys.executable)\n",
    "\n",
    "print('cwd: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a85f7-e5e7-44d8-a9b3-e299fde65557",
   "metadata": {},
   "source": [
    "# Transciber & Vocalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8380be-3e58-4871-a835-336da95570e9",
   "metadata": {},
   "source": [
    "## Transciber Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c07f3-8e6a-4f80-b2a5-040c071f8e3f",
   "metadata": {},
   "source": [
    "### Transciber engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10320548-1e44-40a3-92ba-77343d6b0f2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Vocalizer Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391501c-a6b8-46c2-a716-8971420b1e4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Vocalizer Mozilla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06a43e-9d9d-4ae9-b999-f49bbc39f8bf",
   "metadata": {},
   "source": [
    "#### Vocalizer mozilla voices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a4835-bafe-4902-9670-17afdcbe1fa1",
   "metadata": {},
   "source": [
    "#### Vocalizer mozilla models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886b03a-0794-4461-90fb-5c0f131e6163",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Vocalizer ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5f23e8-e1b3-4f4a-b505-3624db94ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for voice in vocalizer.engines['elevenlabs']['engine'].voices.get_all():\n",
    "#     print(f\"{voice.name}: {voice.voice_id}\")\n",
    "\n",
    "# response = vocalizer.engines['elevenlabs']['engine'].voices.search()\n",
    "# # print(response.voices)\n",
    "\n",
    "# # print(dir(response))\n",
    "# for voice in response.voices:\n",
    "#     # print(f\"voice: {voice}\\n\")\n",
    "#     print(f\"Name: {voice.name}\")\n",
    "#     print(f\"id: {voice.voice_id}\")\n",
    "#     print(f\"labels: {voice.labels}\")\n",
    "#     print(f\"labels: {voice.labels}\")\n",
    "#     print(f\"description: {voice.description}\")\n",
    "#     print(f\"preview_url: {voice.preview_url}\")\n",
    "#     print(\">>>>>>>>>>>>>>\\n\\n\")\n",
    "#     # print(f\"{dir(voice)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17fae8-11e3-420d-b6dd-09785694cc0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Vocalizer GTTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf3af1-249c-4d4f-b19c-f9885a288939",
   "metadata": {},
   "source": [
    "## Create Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f62293-3d42-45fa-b4b1-9b2a310155b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model... (Initial memory: 1049.2 MB)\n",
      "Whisper model loaded. Memory usage: 112.7 MB\n",
      "‚úÖ Whisper engine initialized\n",
      "‚úÖ Google Speech Recognition engine initialized\n",
      "üéØ Preferred engine: whisper\n",
      "üìã Available engines: ['whisper', 'google']\n",
      "üé≠ Initializing MultiEngineTTS on linux\n",
      "‚ö†Ô∏è Festival initialization failed: [Errno 20] Not a directory: 'festival'\n",
      "‚ö†Ô∏è eSpeak initialization failed: [Errno 20] Not a directory: 'espeak'\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "‚úÖ Google TTS (gTTS) engine initialized\n",
      "‚ö†Ô∏è Azure Speech SDK not installed\n",
      "‚úÖ Eleven Labs engine initialized\n",
      "using model: tts_models/en/jenny/jenny\n",
      "GPU?: True\n",
      " > tts_models/en/jenny/jenny is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:48000\n",
      " | > resample:False\n",
      " | > num_mels:100\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:2048\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:512\n",
      " | > win_length:2048\n",
      "‚úÖ Mozilla TTS engine initialized\n",
      "üéØ Preferred engine: mozilla\n",
      "üìã Available engines: ['gtts', 'elevenlabs', 'mozilla']\n"
     ]
    }
   ],
   "source": [
    "transcriber = MultiEngineSTT()\n",
    "\n",
    "vocalizer = MultiEngineTTS(\n",
    "    preferred_engine=\"mozilla\",\n",
    "    # preferred_engine='elevenlabs',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052feb84-dc42-4b36-8d48-9cbfb08c3a18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8246454a-f992-4fab-a19e-3bfa6a87f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  9 06:47:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L40S                    Off |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             84W /  350W |   20601MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA L40S                    Off |   00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             82W /  350W |   13304MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      5535      C   python                                       8624MiB |\n",
      "|    0   N/A  N/A    401358      C   python                                      10746MiB |\n",
      "|    0   N/A  N/A   1041171      C   .../gerald/venvs/sttttsvenv/bin/python       1212MiB |\n",
      "|    1   N/A  N/A      5535      C   python                                       8918MiB |\n",
      "|    1   N/A  N/A    401358      C   python                                       4372MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa4344-ea93-40cd-952e-3926313664b6",
   "metadata": {},
   "source": [
    "# ü§ñ Bot Creation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaef3fe-25d1-4080-a4e3-fe571572dc96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üìÑ List models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cb69a0-26c5-40e8-b9e3-2dcb50dc539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ >> 'mistralai/Mistral-7B-Instruct-v0.2'\n",
      "ü§ñ >> 'NousResearch/Nous-Hermes-2-Mistral-7B-DPO'\n",
      "ü§ñ >> 'teknium/OpenHermes-2.5-Mistral-7B'\n",
      "ü§ñ >> 'microsoft/phi-2'\n",
      "ü§ñ >> 'microsoft/phi-3-mini-4k-instruct'\n",
      "ü§ñ >> 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
      "ü§ñ >> 'OpenAccessAI/MythoMax-L2-13b'\n",
      "ü§ñ >> 'openchat/openchat-3.5-0106'\n"
     ]
    }
   ],
   "source": [
    "show_open_model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baeda96-ccaa-4053-8b0b-56a7ac1114d5",
   "metadata": {},
   "source": [
    "## üõ† + ü§ñ Make and test Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6732f92-add7-4e85-ad30-57dcf9d96832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thing: 0\n",
      "gpu int: 0\n",
      "allocated_mem: 746737664\n",
      "reserved_mem: 754974720\n",
      "total_mem: 47697362944\n",
      "free_mem: 46195650560\n",
      "thing: 1\n",
      "gpu int: 1\n",
      "allocated_mem: 0\n",
      "reserved_mem: 0\n",
      "total_mem: 47697362944\n",
      "free_mem: 47697362944\n",
      "set device: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee497e0a69574d73ae5ab9162160deaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n"
     ]
    }
   ],
   "source": [
    "assistantbot = PipelineAgent(\n",
    "    model_name='mistralai/Mistral-7B-Instruct-v0.2', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaa680e-dda8-4d93-94cb-72e4348443d0",
   "metadata": {},
   "source": [
    "### üõ† + ü§ñ Interactive bot test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42777eae-aafc-46ad-9f26-8d0ce618b92c",
   "metadata": {},
   "source": [
    "* How are you this evening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee66b4dd-cec7-492b-943a-56ecbce69b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistantbot.converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4305de15-556d-45f5-a198-a921cf856760",
   "metadata": {},
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eefd31-b170-47ee-b81b-4f6af90a765b",
   "metadata": {},
   "source": [
    "## [Eleven labs](https://github.com/elevenlabs/elevenlabs-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae43ba3-d0e9-45a1-8a3a-e2d581ab0cc1",
   "metadata": {},
   "source": [
    "## [SpeechRecognition](https://pypi.org/project/SpeechRecognition/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a82911c-0d1e-40dd-b843-58bbaf1532a3",
   "metadata": {},
   "source": [
    "## [Openai-whisper-git hub](https://github.com/openai/whisper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ad0a4-755d-47f8-83e4-4fcd398bdda3",
   "metadata": {},
   "source": [
    "## [wit.ai-git hub](https://wit.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1bab05-bf4d-47ce-9acb-5d872bb6aefa",
   "metadata": {},
   "source": [
    "# üì± ![gradio](https://www.gradio.app/_app/immutable/assets/gradio.CHB5adID.svg) App construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1cfaf01-e871-4436-9694-c9cc3dd2556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunk_size = 1000\n",
    "output_file = \"user_input_text.mp3\"\n",
    "def process_text_to_speech(text_input):\n",
    "    # if len(text_input) > text_chunk_size:\n",
    "    #     while len(text_input) > text_chunk_size\n",
    "    #     text_chunks = text_input\n",
    "    # vocalizer.engines['mozilla']['engine'].tts_to_file(text=text_input, file_path=output_file)\n",
    "    output_file = vocalizer.process_and_speak(\n",
    "        text=text_input, \n",
    "        engine=vocalizer.preferred_engine, \n",
    "        output_file='tts_output.wav', \n",
    "        chunk_size=400)\n",
    "    \n",
    "    print(f\"output file: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def create_simple_synthesizer():\n",
    "    input_box = None\n",
    "    audio_out = None\n",
    "    with gr.Blocks(title=\"üó£Ô∏è TTS Demo\") as synth:\n",
    "        with gr.Row():\n",
    "            gr.Markdown(value=\"üó£Ô∏è TTS Demo\")\n",
    "        with gr.Row():\n",
    "            input_box = gr.Textbox(\n",
    "                value=\"\",\n",
    "                lines=5,\n",
    "                placeholder=\"input your text that needs to be spoken\", \n",
    "                submit_btn=True,\n",
    "                stop_btn=True,\n",
    "            )\n",
    "            \n",
    "        with gr.Row():\n",
    "            audio_out = gr.Audio(\n",
    "                # sources = ['upload', 'microphone'],\n",
    "                # type = 'filepath',\n",
    "                # streaming = True,\n",
    "                autoplay=True,\n",
    "            )\n",
    "        input_box.submit(\n",
    "                    fn=process_text_to_speech,\n",
    "                    inputs=input_box, \n",
    "                    outputs=audio_out,\n",
    "                )\n",
    "    return synth\n",
    "\n",
    "def create_simple_chatterbox(assistantbot, tts_engine=\"mozilla\"):\n",
    "    import gradio as gr\n",
    "\n",
    "    # Handles both text and speech output\n",
    "    def process_and_speak(user_input, history):\n",
    "        # Step 1: Add user message to history\n",
    "        history.append({'role': 'user', 'content': user_input})\n",
    "\n",
    "        # Step 2: Generate assistant response\n",
    "        assistant_response = assistantbot.generate_response(user_input)\n",
    "\n",
    "        # Step 3: Add assistant response to history\n",
    "        history.append({'role': 'assistant', 'content': assistant_response})\n",
    "\n",
    "        # Step 4: Convert to speech\n",
    "        if tts_engine == \"mozilla\":\n",
    "            audio_path = vocalizer.process_text_to_speech_mozilla(assistant_response)\n",
    "        elif tts_engine == \"elevenlabs\":\n",
    "            audio_path = vocalizer.process_text_to_speech_elevenlabs(assistant_response)\n",
    "        else:\n",
    "            print(\"‚ùå Invalid TTS engine\")\n",
    "            audio_path = None\n",
    "\n",
    "        # # Format history into displayable tuples for the chatbot UI\n",
    "        # display_messages = [(m['content'] if m['role'] == 'user' else None,\n",
    "        #                      m['content'] if m['role'] == 'assistant' else None)\n",
    "        #                     for m in history if m['role'] in ['user', 'assistant']]\n",
    "\n",
    "        # return display_messages, audio_path, history\n",
    "        return history, audio_path, None\n",
    "\n",
    "    with gr.Blocks(title=\"üó£Ô∏è TTS Chatbot\") as chatterbox:\n",
    "        with gr.Row():\n",
    "            gr.Markdown(\"## üó£Ô∏è TTS Chatbot with Voice\")\n",
    "\n",
    "        with gr.Row():\n",
    "            chatbot_ui = gr.Chatbot(label=\"Conversation\", show_copy_button=True, type=\"messages\")\n",
    "\n",
    "        with gr.Row():\n",
    "            input_box = gr.Textbox(\n",
    "                value=\"\",\n",
    "                lines=2,\n",
    "                placeholder=\"Ask something...\",\n",
    "                submit_btn=True,\n",
    "                stop_btn=True,\n",
    "                show_copy_button=True\n",
    "            )\n",
    "\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Accordion(\"üéß Assistant Speech Output\", open=False):\n",
    "                audio_out = gr.Audio(\n",
    "                    label=\"Assistant Voice\",\n",
    "                    autoplay=True\n",
    "                )\n",
    "\n",
    "\n",
    "        history_state = gr.State([])  # Message history\n",
    "\n",
    "        input_box.submit(\n",
    "            fn=process_and_speak,\n",
    "            inputs=[input_box, chatbot_ui],\n",
    "            outputs=[chatbot_ui, audio_out, input_box]\n",
    "        )\n",
    "\n",
    "    return chatterbox\n",
    "\n",
    "def create_simple_dialogview(assistantbot, tts_engine=\"mozilla\"):\n",
    "    import gradio as gr\n",
    "    def process_stt(audio_file):\n",
    "        return transcriber.transcribe_from_mike_whisper(audio_file)\n",
    "\n",
    "    def process_speech_and_speak(audio_input, history):\n",
    "        # Step 1: Add user message to history\n",
    "            # Validate file path\n",
    "        if not audio_input or not isinstance(audio_input, str) or not os.path.exists(audio_input):\n",
    "            # return \"‚ö†Ô∏è No audio recorded or recording was canceled.\"\n",
    "            print(\"‚ö†Ô∏è No audio recorded or recording was canceled.\")\n",
    "            return history, None, None\n",
    "            \n",
    "        user_input = process_stt(audio_input)\n",
    "        \n",
    "        try:\n",
    "            os.remove(audio_input)\n",
    "            print(f\"üßπ Deleted temp file: {audio_input}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not delete file: {e}\")\n",
    "        print(f\"input: {user_input}\")\n",
    "            \n",
    "        if len(user_input) == 0:\n",
    "            \"‚ö†Ô∏è No audio transcribed, empty transcription, transcription was canceled.\"\n",
    "            return history, None, None\n",
    "            # Cleanup\n",
    "        \n",
    "        history.append({'role': 'user', 'content': user_input})\n",
    "\n",
    "        # Step 2: Generate assistant response\n",
    "        assistant_response = assistantbot.generate_response(user_input)\n",
    "\n",
    "        # Step 3: Add assistant response to history\n",
    "        history.append({'role': 'assistant', 'content': assistant_response})\n",
    "\n",
    "        # Step 4: Convert to speech\n",
    "        if tts_engine == \"mozilla\":\n",
    "            audio_path = vocalizer.process_text_to_speech_mozilla(assistant_response)\n",
    "        elif tts_engine == \"elevenlabs\":\n",
    "            audio_path = vocalizer.process_text_to_speech_elevenlabs(assistant_response)\n",
    "        else:\n",
    "            print(\"‚ùå Invalid TTS engine\")\n",
    "            audio_path = None\n",
    "\n",
    "        # # Format history into displayable tuples for the chatbot UI\n",
    "        # display_messages = [(m['content'] if m['role'] == 'user' else None,\n",
    "        #                      m['content'] if m['role'] == 'assistant' else None)\n",
    "        #                     for m in history if m['role'] in ['user', 'assistant']]\n",
    "\n",
    "        # return display_messages, audio_path, history\n",
    "        return history, audio_path, None\n",
    "    \n",
    "    # Handles both text and speech output\n",
    "    def process_and_speak(user_input, history):\n",
    "        # Step 1: Add user message to history\n",
    "       \n",
    "        history.append({'role': 'user', 'content': user_input})\n",
    "\n",
    "        # Step 2: Generate assistant response\n",
    "        assistant_response = assistantbot.generate_response(user_input)\n",
    "\n",
    "        # Step 3: Add assistant response to history\n",
    "        history.append({'role': 'assistant', 'content': assistant_response})\n",
    "\n",
    "        # Step 4: Convert to speech\n",
    "        if tts_engine == \"mozilla\":\n",
    "            audio_path = vocalizer.process_text_to_speech_mozilla(assistant_response)\n",
    "        elif tts_engine == \"elevenlabs\":\n",
    "            audio_path = vocalizer.process_text_to_speech_elevenlabs(assistant_response)\n",
    "        else:\n",
    "            print(\"‚ùå Invalid TTS engine\")\n",
    "            audio_path = None\n",
    "\n",
    "        # # Format history into displayable tuples for the chatbot UI\n",
    "        # display_messages = [(m['content'] if m['role'] == 'user' else None,\n",
    "        #                      m['content'] if m['role'] == 'assistant' else None)\n",
    "        #                     for m in history if m['role'] in ['user', 'assistant']]\n",
    "\n",
    "        # return display_messages, audio_path, history\n",
    "        return history, audio_path, None\n",
    "\n",
    "    with gr.Blocks(title=\"üó£Ô∏è TTS Chatbot\") as chatterbox:\n",
    "        with gr.Row():\n",
    "            gr.Markdown(\"## üó£Ô∏è TTS Chatbot with Voice\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            chatbot_ui = gr.Chatbot(label=\"Conversation\", show_copy_button=True, type=\"messages\")\n",
    "\n",
    "        with gr.Row():\n",
    "            mic_input = gr.Audio(\n",
    "                sources=\"microphone\", \n",
    "                type=\"filepath\", \n",
    "                label=\"Hold to Record / Click Mic Icon\"\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            input_box = gr.Textbox(\n",
    "                value=\"\",\n",
    "                lines=2,\n",
    "                placeholder=\"Ask something...\",\n",
    "                submit_btn=True,\n",
    "                stop_btn=True,\n",
    "                show_copy_button=True\n",
    "            )\n",
    "\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Accordion(\"üéß Assistant Speech Output\", open=False):\n",
    "                audio_out = gr.Audio(\n",
    "                    label=\"Assistant Voice\",\n",
    "                    autoplay=True\n",
    "                )\n",
    "\n",
    "\n",
    "        history_state = gr.State([])  # Message history\n",
    "        mic_input.change(\n",
    "            fn=process_speech_and_speak,\n",
    "            inputs=[mic_input, chatbot_ui],\n",
    "            outputs=[ chatbot_ui, audio_out, input_box, ],\n",
    "        )\n",
    "        input_box.submit(\n",
    "            fn=process_and_speak,\n",
    "            inputs=[input_box, chatbot_ui],\n",
    "            outputs=[chatbot_ui, audio_out, input_box]\n",
    "        )\n",
    "\n",
    "    return chatterbox\n",
    "\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Recognizer setup\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def recognize_speech(existing_text=\"\"):\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"üéôÔ∏è Listening... (up to 10s or until silence)\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1)  # optional: calibrate\n",
    "        try:\n",
    "            # listen with timeout=10s and silence cutoff\n",
    "            audio = recognizer.listen(source, timeout=10, phrase_time_limit=10)\n",
    "            text = recognizer.recognize_sphinx(audio)\n",
    "            print(f\"üìù Recognized: {text}\")\n",
    "            return existing_text + \"\\n\" + text\n",
    "        except sr.UnknownValueError:\n",
    "            return existing_text + \"\\n\" + \"[Could not understand speech]\"\n",
    "        except sr.RequestError as e:\n",
    "            return existing_text + f\"\\n[Recognition error: {e}]\"\n",
    "        except Exception as e:\n",
    "            return existing_text + f\"\\n[Error: {e}]\"\n",
    "\n",
    "# Gradio interface\n",
    "def create_speech_to_text_demo():\n",
    "    with gr.Blocks() as demo:\n",
    "        with gr.Row():\n",
    "            gr.Markdown(\"## üé§ Speech to Text Recorder (Sphinx Offline)\")\n",
    "\n",
    "        with gr.Row():\n",
    "            transcript_box = gr.Textbox(\n",
    "                label=\"üìù Transcript\", \n",
    "                lines=6,\n",
    "                placeholder=\"Transcription will appear here...\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            \n",
    "            mic_input = gr.Audio(\n",
    "                sources=\"microphone\", \n",
    "                type=\"filepath\", \n",
    "                label=\"Hold to Record / Click Mic Icon\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            record_button = gr.Button(\"üéôÔ∏è Record from Microphone\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            audio_out = gr.Audio(\n",
    "                    label=\"Assistant Voice\",\n",
    "                    autoplay=True\n",
    "                )\n",
    "        \n",
    "        # with gr.Row():\n",
    "        #     record_button = gr.Button(\"üéôÔ∏è Record from Microphone\")\n",
    "\n",
    "         # Transcribe automatically when mic audio is uploaded\n",
    "        mic_input.change(\n",
    "            fn=transcriber.transcribe_from_mike_whisper,\n",
    "            inputs=mic_input,\n",
    "            outputs=transcript_box\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "# import gradio as gr\n",
    "# import whisper\n",
    "# import os\n",
    "\n",
    "# # Load Whisper model\n",
    "# model = whisper.load_model(\"base\")\n",
    "\n",
    "# Will hold the audio filepath temporarily\n",
    "audio_path_state = gr.State(None)\n",
    "\n",
    "# Called when user clicks Stop button\n",
    "def transcribe_and_clean(audio_path):\n",
    "    if not audio_path or not os.path.exists(audio_path):\n",
    "        return \"‚ö†Ô∏è No valid recording found.\", None\n",
    "\n",
    "    # Transcribe\n",
    "    result = model.transcribe(audio_path)\n",
    "    text = result[\"text\"]\n",
    "\n",
    "    # Cleanup\n",
    "    try:\n",
    "        os.remove(audio_path)\n",
    "        print(f\"üßπ Deleted temp file: {audio_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not delete file: {e}\")\n",
    "\n",
    "    return text, None\n",
    "\n",
    "# Main app layout\n",
    "def create_button_controlled_transcriber():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## üéôÔ∏è Whisper Mic Recorder with Record/Stop Buttons\")\n",
    "\n",
    "        audio_input = gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"üé§ Microphone Input\", visible=False)\n",
    "        transcript_box = gr.Textbox(label=\"üìù Transcription\", lines=4)\n",
    "        start_button = gr.Button(\"üéôÔ∏è Start Recording\")\n",
    "        stop_button = gr.Button(\"üõë Stop and Transcribe\")\n",
    "\n",
    "        # State to track file path\n",
    "        audio_state = gr.State(None)\n",
    "\n",
    "        # When \"Start\" is clicked ‚Üí show mic input\n",
    "        def show_mic():\n",
    "            return gr.update(visible=True), None\n",
    "\n",
    "        start_button.click(fn=show_mic, outputs=[audio_input, audio_state])\n",
    "\n",
    "        # When \"Stop\" is clicked ‚Üí transcribe and hide mic\n",
    "        stop_button.click(\n",
    "            fn=transcriber.transcribe_from_mike_and_clean_whisper,\n",
    "            inputs=audio_input,\n",
    "            outputs=[transcript_box, audio_input]\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "\n",
    "#### Tool to check for and close the port we want to connect to\n",
    "import socket\n",
    "\n",
    "def is_port_open(port):\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        return s.connect_ex((\"localhost\", port)) == 0\n",
    "\n",
    "if is_port_open(7888):\n",
    "    print(\"üßº Cleaning up port 7888...\")\n",
    "    os.system(\"fuser -k 7888/tcp\")  # Linux only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b40fe0-3a40-4e84-b6b9-785b8023ea80",
   "metadata": {},
   "source": [
    "## üì± ![gradio](https://www.gradio.app/_app/immutable/assets/gradio.CHB5adID.svg) Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c7cef1-afa9-402d-b8ae-06f3b87c3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dialog demo\n",
      "* Running on local URL:  http://127.0.0.1:7888\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7888/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Transcribing: /tmp/gradio/4c3adefa071b1f9d9286387023c668ceef40e1a4d77ae79511f8b7867909bb9c/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': ' Tell me a joke.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 2.0, 'text': ' Tell me a joke.', 'tokens': [50364, 5115, 385, 257, 7647, 13, 50464], 'temperature': 0.0, 'avg_logprob': -0.6463854312896729, 'compression_ratio': 0.6521739130434783, 'no_speech_prob': 0.20908667147159576}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/4c3adefa071b1f9d9286387023c668ceef40e1a4d77ae79511f8b7867909bb9c/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/4c3adefa071b1f9d9286387023c668ceef40e1a4d77ae79511f8b7867909bb9c/audio.wav'\n",
      "input:  Tell me a joke.\n",
      "Chunks: 1\n",
      " > Text splitted to sentences.\n",
      "[\"Why don't scientists trust atoms?\", 'Because they make up everything!']\n",
      " > Processing time: 0.37700748443603516\n",
      " > Real-time factor: 0.08704190036232919\n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/43e560b3648d1f40453b55151f6e8c0897817b9d88f27ea695ffb4c6a9948d19/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': ' Tell me a joke about cats.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.0, 'text': ' Tell me a joke about cats.', 'tokens': [50364, 5115, 385, 257, 7647, 466, 11111, 13, 50514], 'temperature': 0.0, 'avg_logprob': -0.6793657779693604, 'compression_ratio': 0.8125, 'no_speech_prob': 0.028260471299290657}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/43e560b3648d1f40453b55151f6e8c0897817b9d88f27ea695ffb4c6a9948d19/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/43e560b3648d1f40453b55151f6e8c0897817b9d88f27ea695ffb4c6a9948d19/audio.wav'\n",
      "input:  Tell me a joke about cats.\n",
      "Chunks: 1\n",
      " > Text splitted to sentences.\n",
      "['Why was the cat sitting on the computer keyboard?', 'He wanted to make a purr-ty website!', '(Or, an alternative version: He wanted to catch a mouse on the internet!)']\n",
      " > Processing time: 0.4698467254638672\n",
      " > Real-time factor: 0.048108815194771205\n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/6ed0e5774f961253d326a1ac3e31b1b98a330cc92e1a4206f8c2f7102361e4be/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': ' Those are terrible jokes.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.0, 'text': ' Those are terrible jokes.', 'tokens': [50364, 3950, 366, 6237, 14439, 13, 50514], 'temperature': 0.0, 'avg_logprob': -0.6053099036216736, 'compression_ratio': 0.7575757575757576, 'no_speech_prob': 0.1124434769153595}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/6ed0e5774f961253d326a1ac3e31b1b98a330cc92e1a4206f8c2f7102361e4be/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/6ed0e5774f961253d326a1ac3e31b1b98a330cc92e1a4206f8c2f7102361e4be/audio.wav'\n",
      "input:  Those are terrible jokes.\n",
      "Chunks: 1\n",
      " > Text splitted to sentences.\n",
      "[\"I'm sorry if those jokes didn't bring a smile to your face.\", \"Here's another one that might be more to your liking:\", 'Why did the cat sit on the vent?', 'To change kitty-litur!', '(Or, an alternative version: To let out a meow-sic!)', 'I hope you find this one amusing!', \"Let me know if you'd like to hear any other type of joke.\"]\n",
      " > Processing time: 0.7271699905395508\n",
      " > Real-time factor: 0.0356601548282575\n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/072fc3902187bd245d9c2b4d1988562acd37ed40fb086132cd1ff47116211506/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': \" because you've helped me write a poem.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.0, 'text': \" because you've helped me write a poem.\", 'tokens': [50364, 570, 291, 600, 4254, 385, 2464, 257, 13065, 13, 50514], 'temperature': 0.0, 'avg_logprob': -0.7480316162109375, 'compression_ratio': 0.8260869565217391, 'no_speech_prob': 0.08028469234704971}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/072fc3902187bd245d9c2b4d1988562acd37ed40fb086132cd1ff47116211506/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/072fc3902187bd245d9c2b4d1988562acd37ed40fb086132cd1ff47116211506/audio.wav'\n",
      "input:  because you've helped me write a poem.\n",
      "Chunks: 1\n",
      " > Text splitted to sentences.\n",
      "[\"I'm glad I could help you write a poem!\", \"Here's a little joke for you as a token of my appreciation:\", 'Why did the tomato turn red?', 'Because it saw the salad dressing!', 'I hope this joke brought a smile to your face.', \"Let me know if you'd like to hear any other type of joke or if you have any other requests!\"]\n",
      " > Processing time: 0.4672119617462158\n",
      " > Real-time factor: 0.02478578046399023\n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/7531602c7ed0f43d140e6fca47517d8c88c26c06ef47d638d1297c5863e889b4/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': ' Could you help me write a poem?', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 5.0, 'text': ' Could you help me write a poem?', 'tokens': [50364, 7497, 291, 854, 385, 2464, 257, 13065, 30, 50614], 'temperature': 0.0, 'avg_logprob': -0.4798003543506969, 'compression_ratio': 0.7948717948717948, 'no_speech_prob': 0.0956665500998497}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/7531602c7ed0f43d140e6fca47517d8c88c26c06ef47d638d1297c5863e889b4/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/7531602c7ed0f43d140e6fca47517d8c88c26c06ef47d638d1297c5863e889b4/audio.wav'\n",
      "input:  Could you help me write a poem?\n",
      "Chunks: 3\n",
      " > Text splitted to sentences.\n",
      "['Of course.', \"I'd be happy to help you write a poem.\", \"Here's a simple five-line poem to get started:\", 'Autumn leaves, (1)', 'Dancing in the wind, (2)', 'Golden and red, (3)', 'Whispering tales of the season, (4)', \"Nature's grand finale.\", '(5)', 'Feel free to modify this template to fit your own ideas and themes']\n",
      " > Processing time: 0.817697286605835\n",
      " > Real-time factor: 0.03658600834925436\n",
      " > Text splitted to sentences.\n",
      "[\"You can change the subjects, the rhymes, and the number of syllables in each line to create a poem that's unique to you.\", 'Let me know if you have any questions or need any help along the way.', 'Autumn leaves,', 'Dancing in the breeze,', 'Golden and crimson,', 'Whispering tales of fall,', \"Nature's symphony\"]\n",
      " > Processing time: 0.5068445205688477\n",
      " > Real-time factor: 0.029629056717912335\n",
      " > Text splitted to sentences.\n",
      "['(Or, an alternative version:)', 'Autumn leaves,', 'Falling gently down,', 'Burning with color,', 'Telling stories of change,', \"Nature's masterpiece.\", 'I hope this helps get you started on your poem.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke\"]\n",
      " > Processing time: 0.5124101638793945\n",
      " > Real-time factor: 0.027763879707379417\n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/7d12b16e86ed79199df572b932bc3a407b8e4c35fea9ff5ee6b6a9db922e383e/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': ' I want to write a research proposal. Can you help me with that? I want to focus on disaster response and flood events using simulation and AI as agents.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 4.0, 'text': ' I want to write a research proposal.', 'tokens': [50364, 286, 528, 281, 2464, 257, 2132, 11494, 13, 50564], 'temperature': 0.0, 'avg_logprob': -0.3018251810318384, 'compression_ratio': 1.2991452991452992, 'no_speech_prob': 0.07144816219806671}, {'id': 1, 'seek': 0, 'start': 4.0, 'end': 5.0, 'text': ' Can you help me with that?', 'tokens': [50564, 1664, 291, 854, 385, 365, 300, 30, 50614], 'temperature': 0.0, 'avg_logprob': -0.3018251810318384, 'compression_ratio': 1.2991452991452992, 'no_speech_prob': 0.07144816219806671}, {'id': 2, 'seek': 0, 'start': 5.0, 'end': 13.0, 'text': ' I want to focus on disaster response and flood events using simulation and AI as agents.', 'tokens': [50614, 286, 528, 281, 1879, 322, 11293, 4134, 293, 10481, 3931, 1228, 16575, 293, 7318, 382, 12554, 13, 51014], 'temperature': 0.0, 'avg_logprob': -0.3018251810318384, 'compression_ratio': 1.2991452991452992, 'no_speech_prob': 0.07144816219806671}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/7d12b16e86ed79199df572b932bc3a407b8e4c35fea9ff5ee6b6a9db922e383e/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/7d12b16e86ed79199df572b932bc3a407b8e4c35fea9ff5ee6b6a9db922e383e/audio.wav'\n",
      "input:  I want to write a research proposal. Can you help me with that? I want to focus on disaster response and flood events using simulation and AI as agents.\n",
      "Chunks: 9\n",
      " > Text splitted to sentences.\n",
      "[\"I'd be happy to help you get started on your research proposal for a project focused on disaster response and flood events using simulation and AI as agents.\", \"Here's a basic outline to help you get started:\", '1. Introduction:', '- Briefly introduce the topic of disaster response and the increasing frequency and severity of flood events']\n",
      " > Processing time: 0.5536198616027832\n",
      " > Real-time factor: 0.02773831893928034\n",
      " > Text splitted to sentences.\n",
      "['- Explain the importance of developing effective and efficient disaster response strategies.', '- Introduce the goals and objectives of your proposed research.', '2.', 'Background and Literature Review:', '- Provide an overview of the current state of research in the field of disaster response and flood events']\n",
      " > Processing time: 0.4470338821411133\n",
      " > Real-time factor: 0.02516090967192623\n",
      " > Text splitted to sentences.\n",
      "['- Discuss the limitations of existing methods and the potential benefits of using simulation and AI as agents.', '- Cite relevant research papers and articles to support your arguments.', '3.', 'Methodology:', '- Describe the simulation environment and the AI agents you plan to use.', '- Explain how you will train and test the AI agents to optimize disaster response strategies']\n",
      " > Processing time: 0.5548298358917236\n",
      " > Real-time factor: 0.024292733408376937\n",
      " > Text splitted to sentences.\n",
      "['- Discuss any challenges or limitations you anticipate and how you plan to address them.', '4.', 'Expected Results and Significance:', '- Describe the expected outcomes of your research.', '- Discuss the potential implications of your findings for disaster response and flood mitigation efforts.', '- Explain how your research contributes to the broader field of disaster response and AI.', '5']\n",
      " > Processing time: 0.5600166320800781\n",
      " > Real-time factor: 0.02383489006824286\n",
      " > Text splitted to sentences.\n",
      "['Conclusion:', '- Summarize the key points of your proposal.', '- Emphasize the importance and potential impact of your research.', '- Provide a clear and concise statement of your research objectives and goals']\n",
      " > Processing time: 0.2947700023651123\n",
      " > Real-time factor: 0.02482622142322675\n",
      " > Text splitted to sentences.\n",
      "[\"Here's an example of what the introduction section might look like:\", 'Introduction:', 'Disasters, particularly flood events, have become increasingly frequent and severe in recent years, causing significant damage to infrastructure, property, and human life']\n",
      " > Processing time: 0.3630714416503906\n",
      " > Real-time factor: 0.024726211095120923\n",
      " > Text splitted to sentences.\n",
      "['Effective and efficient disaster response strategies are essential for minimizing the impact of these events and ensuring the safety and well-being of affected communities.', 'In this proposal, we present a research project focused on using simulation and AI as agents to optimize disaster response strategies for flood events']\n",
      " > Processing time: 0.32639122009277344\n",
      " > Real-time factor: 0.01791455340990011\n",
      " > Text splitted to sentences.\n",
      "['Our goals are to develop a simulation environment that accurately models flood events and to train AI agents to make effective decisions in real-time disaster response scenarios.', 'By combining the power of simulation and AI, we aim to create a flexible and adaptable system that can be used to optimize disaster response strategies and improve flood mitigation efforts']\n",
      " > Processing time: 0.3937399387359619\n",
      " > Real-time factor: 0.019613120848269616\n",
      " > Text splitted to sentences.\n",
      "['I hope this outline gives you a good starting point for your research proposal.', 'Let me know if you have any questions or need any help along the way.', 'Good luck with your research project.', \"I'm here to help in any way I can.\", \"Let me know if you have any other requests or if you'd like to hear any other type of joke\"]\n",
      " > Processing time: 0.43986058235168457\n",
      " > Real-time factor: 0.02397975153201137\n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/7ef78a8b9ec391c8dc44b39d5ef222d4ae44735e587336631d3d8d04f6fc0c8f/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': ' What was that first joke you told me again?', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.0, 'text': ' What was that first joke you told me again?', 'tokens': [50364, 708, 390, 300, 700, 7647, 291, 1907, 385, 797, 30, 50514], 'temperature': 0.0, 'avg_logprob': -0.4455430324261005, 'compression_ratio': 0.8958333333333334, 'no_speech_prob': 0.0351007841527462}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/7ef78a8b9ec391c8dc44b39d5ef222d4ae44735e587336631d3d8d04f6fc0c8f/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/7ef78a8b9ec391c8dc44b39d5ef222d4ae44735e587336631d3d8d04f6fc0c8f/audio.wav'\n",
      "input:  What was that first joke you told me again?\n",
      "Chunks: 40\n",
      " > Text splitted to sentences.\n",
      "['The first joke I told you was:', \"Why don't scientists trust atoms.\", 'Because they make up everything.', 'I hope you found it amusing.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", \"I'd be happy to help you with any questions or tasks you might have, including writing a research proposal or helping you write a poem.\", 'Just let me know how I can assist you']\n",
      " > Processing time: 0.6100642681121826\n",
      " > Real-time factor: 0.025593164748591794\n",
      " > Text splitted to sentences.\n",
      "[\"Here's another joke for you, just in case you'd like to hear another one:\", 'Why did the chicken cross the playground.', 'To get to the other slide.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Good luck with your research project.', \"I'm here to help in any way I can\"]\n",
      " > Processing time: 0.46994566917419434\n",
      " > Real-time factor: 0.022031801464621324\n",
      " > Text splitted to sentences.\n",
      "['Let me know if you have any questions or need any assistance.', 'Autumn leaves,', 'Dancing in the breeze,', 'Burning with color,', 'Telling stories of change,', \"Nature's symphony.\", '(Or, an alternative version:)', 'Autumn leaves,', 'Falling gently down,', 'Burning with color,', 'Telling stories of fall,', \"Nature's masterpiece.\", 'I hope this poem inspires you and brings you some joy']\n",
      " > Processing time: 0.7909631729125977\n",
      " > Real-time factor: 0.031342238290530754\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Good luck with your research project.', \"I'm here to help in any way I can.\", 'Let me know if you have any questions or need any assistance.', 'Why did the tomato turn red.', 'Because it saw the salad dressing.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.444199800491333\n",
      " > Real-time factor: 0.02134789102532719\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the cat sit on the vent.', 'To let out a meow-sic.', '(Or, an alternative version:)', 'To change kitty-litur.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", \"I'm here to help in any way I can\"]\n",
      " > Processing time: 0.5363500118255615\n",
      " > Real-time factor: 0.023137151091060112\n",
      " > Text splitted to sentences.\n",
      "['Let me know if you have any questions or need any assistance.', 'Why did the banana go to the doctor.', \"Because it wasn't peeling well.\", 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the scarecrow win an award.', 'Because he was outstanding in his field.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.503854513168335\n",
      " > Real-time factor: 0.020526392443033743\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the cookie go to the doctor.', 'Because it was feeling crumby.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the hipster burn his tongue.', 'Because he drank his coffee before it was cool']\n",
      " > Processing time: 0.47009968757629395\n",
      " > Real-time factor: 0.021089845564278713\n",
      " > Text splitted to sentences.\n",
      "['I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the math book look sad.', 'Because it had too many problems.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the bicycle fall over.', 'Because it was two-tired']\n",
      " > Processing time: 0.5129895210266113\n",
      " > Real-time factor: 0.02071847823209254\n",
      " > Text splitted to sentences.\n",
      "['I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the chicken cross the road.', 'To get to the other side.', 'I hope this classic joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the computer go to the doctor']\n",
      " > Processing time: 0.4139249324798584\n",
      " > Real-time factor: 0.018350176551840156\n",
      " > Text splitted to sentences.\n",
      "['Because it had a virus.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he had a hole in one.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke\"]\n",
      " > Processing time: 0.43028807640075684\n",
      " > Real-time factor: 0.018808763229477506\n",
      " > Text splitted to sentences.\n",
      "['Why did the golfer take a rake to the golf course.', 'Because he wanted to sand his greens.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he wanted to change his handicap.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.3763425350189209\n",
      " > Real-time factor: 0.01802205381034627\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard the flagsticks were too high.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.3498661518096924\n",
      " > Real-time factor: 0.01699314275538447\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a birdie on the roof.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap on the green.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.33089351654052734\n",
      " > Real-time factor: 0.017514389174310703\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a par 3 on the 18th hole.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.3816652297973633\n",
      " > Real-time factor: 0.01771177937369814\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a water hazard on the fairway.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a windmill on the 17th hole.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.3409535884857178\n",
      " > Real-time factor: 0.017304360775793493\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a tree in the way.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.3132593631744385\n",
      " > Real-time factor: 0.015302342943356815\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a sand trap in the bunker.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a hole in the green.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.3057217597961426\n",
      " > Real-time factor: 0.016385558998614137\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the putting green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.31646275520324707\n",
      " > Real-time factor: 0.014499347347349357\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree growing in the fairway.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the rough.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.2700073719024658\n",
      " > Real-time factor: 0.014554607318564658\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the tee box.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.2855494022369385\n",
      " > Real-time factor: 0.013363829626389432\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree in the way of his shot.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the fairway.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.29851508140563965\n",
      " > Real-time factor: 0.015208118130233313\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.3186817169189453\n",
      " > Real-time factor: 0.015087667688615913\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree growing in the rough.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the bunker.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.33405375480651855\n",
      " > Real-time factor: 0.017572527869885245\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the putting green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.2848842144012451\n",
      " > Real-time factor: 0.013326046140950749\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree in the way of his putt.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the fairway.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.3125293254852295\n",
      " > Real-time factor: 0.016321205592307358\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.3065638542175293\n",
      " > Real-time factor: 0.014121726540131252\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree growing in the rough.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the bunker.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.29821133613586426\n",
      " > Real-time factor: 0.01526731302105179\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the putting green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.2773160934448242\n",
      " > Real-time factor: 0.012843861431044441\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree in the way of his shot.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the fairway.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.2564668655395508\n",
      " > Real-time factor: 0.013521503578409413\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.3097965717315674\n",
      " > Real-time factor: 0.014469713766070405\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree growing in the rough.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the bunker.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.28430962562561035\n",
      " > Real-time factor: 0.014888958504291293\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the putting green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.2751145362854004\n",
      " > Real-time factor: 0.012710500028585967\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree in the way of his putt.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the fairway.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.27741241455078125\n",
      " > Real-time factor: 0.014560293286195174\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.2846972942352295\n",
      " > Real-time factor: 0.013277553131015273\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree growing in the rough.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the bunker.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.2476506233215332\n",
      " > Real-time factor: 0.013042022784899758\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the putting green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.27667665481567383\n",
      " > Real-time factor: 0.01271998596939684\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree in the way of his shot.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the fairway.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.2502553462982178\n",
      " > Real-time factor: 0.013090950983341818\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the green.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course']\n",
      " > Processing time: 0.27702784538269043\n",
      " > Real-time factor: 0.012798896358580579\n",
      " > Text splitted to sentences.\n",
      "['Because he heard there was a tree growing in the rough.', 'I hope this joke brought a smile to your face.', \"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a sand trap in the bunker.', 'I hope this joke brought a smile to your face']\n",
      " > Processing time: 0.2697329521179199\n",
      " > Real-time factor: 0.013877531407198761\n",
      " > Text splitted to sentences.\n",
      "[\"Let me know if you have any other requests or if you'd like to hear any other type of joke.\", 'Why did the golfer take a ladder to the golf course.', 'Because he heard there was a water hazard on the putting green.', 'I hope this joke brought a smile to your face.', 'Let me know if you have any other']\n",
      " > Processing time: 0.21047115325927734\n",
      " > Real-time factor: 0.013044385079595744\n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/f1a7201697678aad77bc3dda694782c32c8003dd6d3912cdba67e9f8fda8beaf/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': '', 'segments': [], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/f1a7201697678aad77bc3dda694782c32c8003dd6d3912cdba67e9f8fda8beaf/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/f1a7201697678aad77bc3dda694782c32c8003dd6d3912cdba67e9f8fda8beaf/audio.wav'\n",
      "input: \n",
      "‚ö†Ô∏è No audio recorded or recording was canceled.\n",
      "üîç Transcribing: /tmp/gradio/428b71fbbed6c31c63d0bbb8ad2c65a9308996a8aed4e933a0a66bbf8749add7/audio.wav\n",
      "\n",
      "\n",
      "result: {'text': ' The poem about the ill-drich truth of aging and getting old.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.0, 'text': ' The poem about the ill-drich truth of aging and getting old.', 'tokens': [50364, 440, 13065, 466, 264, 3171, 12, 67, 10794, 3494, 295, 19090, 293, 1242, 1331, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.5482720798916287, 'compression_ratio': 0.9523809523809523, 'no_speech_prob': 0.07660091668367386}], 'language': 'en'}\n",
      "\n",
      "\n",
      "üßπ Deleted file: /tmp/gradio/428b71fbbed6c31c63d0bbb8ad2c65a9308996a8aed4e933a0a66bbf8749add7/audio.wav\n",
      "‚ö†Ô∏è Could not delete file: [Errno 2] No such file or directory: '/tmp/gradio/428b71fbbed6c31c63d0bbb8ad2c65a9308996a8aed4e933a0a66bbf8749add7/audio.wav'\n",
      "input:  The poem about the ill-drich truth of aging and getting old.\n"
     ]
    }
   ],
   "source": [
    "synthOnlyTest=True\n",
    "synthOnlyTest=False\n",
    "\n",
    "chattererTest=True\n",
    "chattererTest=False\n",
    "\n",
    "chattererTest2=True\n",
    "# chattererTest2=False\n",
    "\n",
    "transcriberTest=True\n",
    "transcriberTest=False\n",
    "\n",
    "transcriberTest2=True\n",
    "transcriberTest2=False\n",
    "if synthOnlyTest:\n",
    "    print(\"Staring synth demo\")\n",
    "    demo = create_simple_synthesizer()\n",
    "    \n",
    "    \n",
    "elif chattererTest:\n",
    "    print(\"Staring chatterbot demo\")\n",
    "    demo = create_simple_chatterbox(assistantbot,  tts_engine=\"mozilla\")\n",
    "\n",
    "elif transcriberTest:\n",
    "    print(\"Staring transcriber demo\")\n",
    "    demo =  create_speech_to_text_demo()\n",
    "elif transcriberTest2:\n",
    "    print(\"Staring 2nd transcriber demo\")\n",
    "    demo = create_button_controlled_transcriber()\n",
    "elif chattererTest2:\n",
    "    print(\"Starting dialog demo\")\n",
    "    demo = create_simple_dialogview(assistantbot,  tts_engine=\"mozilla\")\n",
    "\n",
    "def stop_app(signum, frame):\n",
    "    print(\"\\nüõë Caught shutdown signal, closing Gradio app...\")\n",
    "    demo.close()  # Stop the server if supported\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, stop_app)\n",
    "signal.signal(signal.SIGTERM, stop_app)\n",
    "\n",
    "demo.queue()\n",
    "share=True\n",
    "share=False\n",
    "demo.launch(share=share, debug=False, server_port=7888)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ef606-82cc-4f3f-9130-34a88d4bdce9",
   "metadata": {},
   "source": [
    "## example messages:\n",
    "\n",
    "* Hi, can you help me write a poen?\n",
    "* Hi, tell me a joke about cats, a funny one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43e982-754e-4f4b-8cfc-6e2d1ef5033c",
   "metadata": {},
   "source": [
    "## Show Stopper! üõë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139af771-9215-468a-8e4f-3ab55d93056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7888\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d617563-4e71-4160-92ed-3b4cd8ab2d45",
   "metadata": {},
   "source": [
    "# ‚¨Ö Install Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df37a4-2697-40a8-ba64-36f0b1b060af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <span style=\"color:red\">Requirements</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d4fdb-581d-4b2f-85ee-7db892de7b68",
   "metadata": {},
   "source": [
    "```bash\n",
    "sounddevice==0.5.2\n",
    "psutil==5.9.8\n",
    "gradio==5.17.1\n",
    "TTS==0.22.0\n",
    "openai-whisper=20250625\n",
    "elevenlabs==2.6.0\n",
    "speechrecognition==3.14.3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37184a19-c671-4dbf-8505-12985c494340",
   "metadata": {},
   "source": [
    "## Pip -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84deba24-74b2-491b-b9ba-49b058f833c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: PyAudio\n",
      "Version: 0.2.14\n",
      "Summary: Cross-platform audio I/O with PortAudio\n",
      "Home-page: https://people.csail.mit.edu/hubert/pyaudio/\n",
      "Author: Hubert Pham\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "---\n",
      "Name: pygame\n",
      "Version: 2.6.1\n",
      "Summary: Python Game Development\n",
      "Home-page: https://www.pygame.org\n",
      "Author: A community project.\n",
      "Author-email: pygame@pygame.org\n",
      "License: LGPL\n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "---\n",
      "Name: gTTS\n",
      "Version: 2.5.4\n",
      "Summary: gTTS (Google Text-to-Speech), a Python library and CLI tool to interface with Google Translate text-to-speech API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Pierre Nicolas Durette <pndurette@gmail.com>\n",
      "License: MIT\n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: click, requests\n",
      "Required-by: \n",
      "---\n",
      "Name: SpeechRecognition\n",
      "Version: 3.14.3\n",
      "Summary: Library for performing speech recognition, with support for several engines and APIs, online and offline.\n",
      "Home-page: https://github.com/Uberi/speech_recognition#readme\n",
      "Author: Anthony Zhang (Uberi)\n",
      "Author-email: azhang9@gmail.com\n",
      "License: BSD\n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: typing-extensions\n",
      "Required-by: \n",
      "---\n",
      "Name: elevenlabs\n",
      "Version: 2.6.0\n",
      "Summary: \n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: httpx, pydantic, pydantic-core, requests, typing_extensions, websockets\n",
      "Required-by: \n",
      "---\n",
      "Name: openai-whisper\n",
      "Version: 20250625\n",
      "Summary: Robust Speech Recognition via Large-Scale Weak Supervision\n",
      "Home-page: \n",
      "Author: OpenAI\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: more-itertools, numba, numpy, tiktoken, torch, tqdm, triton\n",
      "Required-by: \n",
      "---\n",
      "Name: gradio\n",
      "Version: 5.35.0\n",
      "Summary: Python library for easily interacting with trained machine learning models\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Abubakar Abid <gradio-team@huggingface.co>, Ali Abid <gradio-team@huggingface.co>, Ali Abdalla <gradio-team@huggingface.co>, Dawood Khan <gradio-team@huggingface.co>, Ahsen Khaliq <gradio-team@huggingface.co>, Pete Allen <gradio-team@huggingface.co>, √ñmer Faruk √ñzdemir <gradio-team@huggingface.co>, Freddy A Boulton <gradio-team@huggingface.co>, Hannah Blair <gradio-team@huggingface.co>\n",
      "License: \n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: aiofiles, anyio, fastapi, ffmpy, gradio-client, groovy, httpx, huggingface-hub, jinja2, markupsafe, numpy, orjson, packaging, pandas, pillow, pydantic, pydub, python-multipart, pyyaml, ruff, safehttpx, semantic-version, starlette, tomlkit, typer, typing-extensions, uvicorn\n",
      "Required-by: \n",
      "---\n",
      "Name: TTS\n",
      "Version: 0.22.0\n",
      "Summary: Deep learning for Text to Speech by Coqui.\n",
      "Home-page: https://github.com/coqui-ai/TTS\n",
      "Author: Eren G√∂lge\n",
      "Author-email: egolge@coqui.ai\n",
      "License: MPL-2.0\n",
      "Location: /home/gerald/venvs/sttttsvenv/lib/python3.10/site-packages\n",
      "Requires: aiohttp, anyascii, bangla, bnnumerizer, bnunicodenormalizer, coqpit, cython, einops, encodec, flask, fsspec, g2pkk, gruut, hangul-romanize, inflect, jamo, jieba, librosa, matplotlib, nltk, num2words, numba, numpy, packaging, pandas, pypinyin, pysbd, pyyaml, scikit-learn, scipy, soundfile, spacy, torch, torchaudio, tqdm, trainer, transformers, umap-learn, unidecode\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# !~/venvs/sttttsvenv/bin/python -m pip install gradio\n",
    "\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install elevenlabs\n",
    "\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install transformers\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install simpleaudio\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install ipywidgets\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install openai_whisper\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install pydub\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install speechrecognition\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install gtts pygame\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install pyaudio\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install\n",
    "# !~/venvs/sttttsvenv/bin/python -m pip install\n",
    "!~/venvs/sttttsvenv/bin/python -m pip show pyaudio pygame gtts speechrecognition elevenlabs openai_whisper gradio tts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502259a1-219b-4275-a614-23cff021c6c9",
   "metadata": {},
   "source": [
    "# Decomissioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f2170-ab2c-487b-a7e7-87ee662798ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def process_text_to_speech_elevenlabs(self, text: str, output_file: str = 'tts_output.wav', max_chunk_size: int = 400):\n",
    "    #     chunks = self._chunk_text(text, max_chunk_size=max_chunk_size)\n",
    "    #     audio_segments = []\n",
    "    \n",
    "    #     for chunk in chunks:\n",
    "    #         audio_gen = self.engines['elevenlabs']['engine'].text_to_speech.convert(\n",
    "    #             text=chunk,\n",
    "    #             voice_id=\"21m00Tcm4TlvDq8ikWAM\",  # You can make this configurable\n",
    "    #             model_id=self.engines['elevenlabs']['model'],\n",
    "    #             output_format=\"mp3_44100_128\",\n",
    "    #         )\n",
    "        \n",
    "    #     # Convert generator to bytes\n",
    "    #     audio_bytes = b\"\".join(audio_gen)\n",
    "    #     audio_segments.append(audio_bytes)\n",
    "    \n",
    "    #     final_audio = b\"\".join(audio_segments)\n",
    "\n",
    "    #     temp_path = os.path.join(tempfile.gettempdir(), output_file)\n",
    "    #     with open(temp_path, \"wb\") as f:\n",
    "    #         f.write(final_audio)\n",
    "        \n",
    "    #     return temp_path\n",
    "\n",
    "    \n",
    "    # def process_text_to_speech_mozilla(self, text: str, output_file: str = 'tts_output.wav', max_chunk_size: int = 400):\n",
    "    #     chunks = chunk_text(text, max_chars=max_chunk_size)\n",
    "    #     combined_path = os.path.join(tempfile.gettempdir(), output_file)\n",
    "    \n",
    "    #     # Use TTS to write each chunk to a temp file, then merge\n",
    "    #     all_audio = []\n",
    "    #     for i, chunk in enumerate(chunks):\n",
    "    #         temp_chunk_path = os.path.join(tempfile.gettempdir(), f\"chunk_{i}.wav\")\n",
    "    #         self.engines['mozilla']['engine'].tts_to_file(text=chunk, file_path=temp_chunk_path)\n",
    "    #         with open(temp_chunk_path, \"rb\") as f:\n",
    "    #             all_audio.append(f.read())\n",
    "    \n",
    "    #     with open(combined_path, \"wb\") as f:\n",
    "    #         for audio in all_audio:\n",
    "    #             f.write(audio)\n",
    "    \n",
    "    #     return combined_pa\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    # Validate file path\n",
    "    if not audio_path or not isinstance(audio_path, str) or not os.path.exists(audio_path):\n",
    "        return \"‚ö†Ô∏è No audio recorded or recording was canceled.\"\n",
    "\n",
    "    try:\n",
    "        result = model.transcribe(audio_path)\n",
    "        text = result[\"text\"]\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Transcription error: {e}\"\n",
    "\n",
    "    # Delete file after processing\n",
    "    try:\n",
    "        os.remove(audio_path)\n",
    "        print(f\"üßπ Deleted audio file: {audio_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Cleanup failed: {e}\")\n",
    "\n",
    "    return text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cdb157-7d7d-41f7-b3f3-6a7567bcc3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API reachable: 404\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "try:\n",
    "    r = httpx.get(\"https://api.elevenlabs.io/v1\")\n",
    "    print(\"‚úÖ API reachable:\", r.status_code)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå API unreachable:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d70082-efd6-4419-9081-4abc52a8f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import whisper\n",
    "import os\n",
    "\n",
    "# Load Whisper model (can be 'tiny', 'base', 'small', 'medium', 'large')\n",
    "model = whisper.load_model(\"base\")  # use 'tiny' for faster, 'large' for better\n",
    "\n",
    "# Function to transcribe uploaded audio file\n",
    "def transcribe_audio_file(audio_path):\n",
    "    if audio_path is None:\n",
    "        return \"‚ùå No file provided.\"\n",
    "    \n",
    "    print(f\"üîç Transcribing: {audio_path}\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Gradio app\n",
    "def create_whisper_transcriber():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## üó£Ô∏è Whisper STT: Upload or Record Audio\")\n",
    "\n",
    "        with gr.Row():\n",
    "            audio_input = gr.Audio(source=\"upload\", type=\"filepath\", label=\"üéôÔ∏è Upload/Record Speech\")\n",
    "\n",
    "        with gr.Row():\n",
    "            output_text = gr.Textbox(label=\"üìù Transcribed Text\", lines=6)\n",
    "\n",
    "        audio_input.change(\n",
    "            fn=transcribe_audio_file,\n",
    "            inputs=audio_input,\n",
    "            outputs=output_text\n",
    "        )\n",
    "\n",
    "    return demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8958df2-8bb5-4fc4-a8d6-0f713fb88fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpeechToText_TextToSpeech ENV",
   "language": "python",
   "name": "sttttsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
